<script src="http://www.google.com/jsapi" type="text/javascript"></script> 
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
    body {
        font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif; 
        font-weight:300;
        font-size:18px;
        margin-left: auto;
        margin-right: auto;
        width: 1100px;
    }
    
    h1 {
        font-size:32px;
        font-weight:300;
    }
    
    .disclaimerbox {
        background-color: #eee;     
        border: 1px solid #eeeeee;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
        padding: 20px;
    }

    video.header-vid {
        height: 140px;
        border: 1px solid black;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
    }
    
    img.header-img {
        height: 140px;
        border: 1px solid black;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
    }
    
    img.rounded {
        border: 1px solid #eeeeee;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
    }
    
    a:link,a:visited
    {
        color: #1367a7;
        text-decoration: none;
    }
    a:hover {
        color: #208799;
    }
    
    td.dl-link {
        height: 160px;
        text-align: center;
        font-size: 22px;
    }
    
    .layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
        box-shadow:
        0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
        5px 5px 0 0px #fff, /* The second layer */
        5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
        10px 10px 0 0px #fff, /* The third layer */
        10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
        15px 15px 0 0px #fff, /* The fourth layer */
        15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
        20px 20px 0 0px #fff, /* The fifth layer */
        20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
        25px 25px 0 0px #fff, /* The fifth layer */
        25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
        margin-left: 10px;
        margin-right: 45px;
    }

    .paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
        box-shadow:
        0px 0px 1px 1px rgba(0,0,0,0.35); /* The top layer shadow */

        margin-left: 10px;
        margin-right: 45px;
    }


    .layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
        box-shadow:
        0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
        5px 5px 0 0px #fff, /* The second layer */
        5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
        10px 10px 0 0px #fff, /* The third layer */
        10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
        margin-top: 5px;
        margin-left: 10px;
        margin-right: 30px;
        margin-bottom: 5px;
    }
    
    .vert-cent {
        position: relative;
        top: 50%;
        transform: translateY(-50%);
    }
    
    hr
    {
        border: 0;
        height: 1px;
        background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
    }
</style>

<html>
<head>
    <title>TalkinNeRF</title>
    <meta property="og:title" content="TalkinNeRF: Animatable Neural Fields for Full-Body Talking Humans" />

    <!-- Get from Google Analytics -->
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src=""></script> 
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'UA-75863369-6');
    </script>
</head>

<body>
    <br>
    <center>
        <span style="font-size:36px"><b>TalkinNeRF: Animatable Neural Fields for<br>Full-Body Talking Humans</b></span><br></br>
        <table align=center>
            <table align=center width=1024px>
                <tr>
                    <td align=center width=256px>
                        <center>
                            <span style="font-size:24px">Aggelina Chatziagapi<sup>1</sup></a></span>
                        </center>
                    </td>
                    <td align=center width=256px>
                        <center>
                            <span style="font-size:24px">Bindita Chaudhuri<sup>3</sup></a></span>
                        </center>
                    </td>
                    <td align=center width=200px>
                        <center>
                            <span style="font-size:24px">Amit Kumar<sup>2</sup></a></span>
                        </center>
                    </td>
                    <td align=center width=256px>
                        <center>
                            <span style="font-size:24px">Rakesh Ranjan<sup>2</sup></a></span>
                        </center>
                    </td>
                    <td align=center width=256px>
                        <center>
                            <span style="font-size:24px">Dimitris Samaras<sup>1</sup></a></span>
                        </center>
                    </td>
                    <td align=center width=256px>
                        <center>
                            <span style="font-size:24px">Nikolaos Sarafianos<sup>2</sup></a></span>
                        </center>
                    </td>
                </tr>
            </table><br>
            <table align=center>
                <tr>
                    <td align=center width=400px>
                        <center>
                            <span style="font-size:22px"><sup>1</sup>Stony Brook University</a></span>
                        </center>
                    </td>
                    <td align=center width=400px>
                        <center>
                            <span style="font-size:22px"><sup>2</sup>Meta Reality Labs</a></span>
                        </center>
                    </td>
                    <td align=center width=400px>
                        <center>
                            <span style="font-size:22px"><sup>3</sup>Flawless AI</a></span>
                        </center>
                    </td>
                </tr>
            </table><br>
            <!-- <table align=center>
                <tr>
                    <td align=center width=1024px>
                        <center>
                            <span style="font-size:24px"><i>arXiv 2024</i></a></span>
                        </center>
                    </td>
                </tr>
            </table><br></br> -->
            <table align=center width=256px>
                <tr>
                    <td align=center width=256px>
                        <center>
                            <span style="font-size:24px">ECCV Workshops 2024</a></span>
                        </center>
                    </td>
                    <!-- <td align=center width=120px>
                        <center>
                            <span style="font-size:24px">[GitHub]</a></span><br>
                        </center>
                    </td> -->
                </tr>
            </table><br></br>
        </table>
    </center>

    <center>
        <table align=center width=1024px>
            <tr>
                <td width=260px>
                    <center>
                        <img class="round" style="width:1024px" src="teaser.png"/>
                    </center>
                <br></br>
                Given monocular videos, TalkinNeRF learns a unified NeRF-based network that
represents the holistic 4D human motion, including body pose, hand articulation, and
facial expressions. It synthesizes high-quality animations of full-body talking humans.
                </td>
            </tr>
        </table>
    </center>

    <br>
    <hr>
    <br>

    <table align=center width=1024px>
        <center><h1>Abstract</h1></center>
        <tr>
            <td>
                We introduce a novel framework that learns a dynamic neural
radiance field (NeRF) for full-body talking humans from monocular
videos. Prior work represents only the body pose or the face. However,
humans communicate with their full body, combining body pose, hand
gestures, as well as facial expressions. In this work, we propose TalkinNeRF, a unified NeRF-based network that represents the holistic 4D
human motion. Given a monocular video of a subject, we learn corresponding
modules for the body, face, and hands, that are combined
together to generate the final result. To capture complex finger articulation,
we learn an additional deformation field for the hands. Our multi-identity
representation enables simultaneous training for multiple subjects,
as well as robust animation under completely unseen poses. It can
also generalize to novel identities, given only a short video as input. We
demonstrate state-of-the-art performance for animating full-body talking
humans, with fine-grained hand articulation and facial expressions.
            </td>
        </tr>
    </table>
    <!-- <br> -->

<!--     <hr>
    <center><h1>Video</h1></center> -->
<!--     <p align="center">
        <iframe width="660" height="395" src="https://www.youtube.com/embed/dQw4w9WgXcQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen align="center"></iframe>
    </p>
 -->
<!--     <table align=center width=800px>
        <br>
        <tr>
            <center>
                <span style="font-size:28px"><a href=''>[Slides]</a>
                </span>
            </center>
        </tr>
    </table>
    <hr>

    <center><h1>Code</h1></center>

    <table align=center width=420px>
        <center>
            <tr>
                <td>
                </td>
            </tr>
        </center>
    </table>
    <table align=center width=400px>
        <tr>
            <td align=center width=400px>
                <center>
                    <td><img class="round" style="width:450px" src="./resources/method_diagram.png"/></td>
                </center>
            </td>
        </tr>
    </table>
    <table align=center width=850px>
        <center>
            <tr>
                <td>
                    Short description if wanted
                </td>
            </tr>
        </center>
    </table>
    <table align=center width=800px>
        <br>
        <tr><center>
            <span style="font-size:28px">&nbsp;<a href='https://github.com/richzhang/webpage-template'>[GitHub]</a>
            </center>
        </span>
    </table> -->
    <br>
    <hr>
    <br>

    <table align=center width=1024px>
       <center><h1>Method</h1></center>
        <tr>
            <td><img style="width:1024px;" src="overview.png">
                <br></br>
                <b>Overview of TalkinNeRF. </b>Given a monocular video of a subject, we learn
                a unified NeRF-based network that represents their holistic 4D motion. Corresponding
                modules for body, face, and hands are combined together, in order to synthesize the
                final full-body talking human. By learning an identity code per video, our method can
                be trained on multiple identities simultaneously.
            </td>
        </tr>
    </table>

    <br>
    <hr>
    <br>
    <table align=center width=1024px>
        <center><h1>Demo</h1></center>
         <tr>
             <td align=center width=1024px>
                 <iframe style="width: 100%; min-height: 576px"
                     src="https://www.youtube.com/embed/AjJT4EFcZ3g">
                 </iframe>
             </td>
     </table>
    
    <br>
    <hr>
    <br>

    <table align=center width=1024px>
        <center><h1>BibTeX</h1></center>
         <tr>
            <td align=left width=1024px>
                If you find our work useful, please consider citing our paper:
            <!-- <td><span style="font-size:14pt"><center> -->
                <!-- <a href="./resources/bibtex.txt">[Bibtex]</a>  -->
            <div>
            <pre style="background-color: #f1f1f1; overflow-x: auto;">
                <code>
                    @inproceedings{chatziagapi2024talkinnerf,
                        title={TalkinNeRF: Animatable Neural Fields for Full-Body Talking Humans},
                        author={Aggelina Chatziagapi and Bindita Chaudhuri and Amit Kumar and Rakesh Ranjan and Dimitris Samaras and Nikolaos Sarafianos},
                        year={2024},
                        booktitle={ECCV Workshops},
                    }
                </code>
            </pre>
        </div>
        </td>
            <!-- </center></td> -->
        </tr>
    </table>

    <!-- <br>
    <hr>
    <br> -->

    <!-- <table align=center width=1024>
        <tr>
            <td width=400px>
                <left>
                    <center><h1>Acknowledgements</h1></center>
                    This work is partly supported  by the Spanish government with the project MoHuCo PID2020-120049RB-I00 and Mar&iacutea de Maeztu Seal of Excellence MDM-2016-0656. This work was also supported by a gift from Adobe, Partner University Fund 4DVision Project, and the SUNY2020 Infrastructure Transportation Security Center.
                </left>
            </td>
        </tr>
    </table> -->

<br>
</body>
</html>

